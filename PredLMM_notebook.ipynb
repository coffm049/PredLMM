{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PredLMM Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Version 1.0*\n",
    "\n",
    "PredLMM Team, August 8, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "PredLMM, which stands for Predictive Process approximated Linear Mixed Model, is a program for performing rapid SNP based heritability estimation with large number of genetically related individuals.\n",
    "\n",
    "See PredLMM's README.md for installation instructions, documentation, code, and a bibliography."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contacts\n",
    "\n",
    "Email one of the developers at slsouvik@gmail.com.\n",
    "Open an issue on GitHub.\n",
    "\n",
    "\n",
    "### Citing PredLMM\n",
    "\n",
    "If you use PredLMM in any published work, please cite the main manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "We will use the phenotype file: \"example_pheno.csv\", covariate file: \"example_covar.csv\". Both the files have 5000 many rows corresponding to 5000 many individuals and 3 columns of which first two are their family and individual IDs. Third column of the phenotype file contains a phenotype vector. The covariate file has only a single covariate vector (third column) of all 1's (intercept term). With the binary files, GRM files are computed using GCTA and are saved under name: \"example_grm\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook preparation and general use\n",
    "\n",
    "We start by loading PredLMM module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Loading  the required Module------------------------------------------\n",
    "from PredLMM.PredLMM_final import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the GCTA-GRM files and construct the $N \\times N$ Genetic Relationship Matrix under the name: GRM_array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------Loading the GRM obtained using GCTA---------------------------------------------------\n",
    "prefix = \"Data/example_grm\"\n",
    "def sum_n_vec(n):\n",
    "    out = [int(0)] * n\n",
    "    for i in range(n):\n",
    "        out[i] = int(((i + 1) * (i + 2) / 2) - 1)\n",
    "    return(out)\n",
    "\n",
    "\n",
    "def ReadGRMBin(prefix, AllN = False):\n",
    "    BinFileName  = prefix + \".grm.bin\"\n",
    "    NFileName = prefix + \".grm.N.bin\"\n",
    "    IDFileName = prefix + \".grm.id\"\n",
    "    dt = np.dtype('f4') # Relatedness is stored as a float of size 4 in the binary file\n",
    "    entry_format = 'f' # N is stored as a float in the binary file\n",
    "    entry_size = calcsize(entry_format)\n",
    "    ## Read IDs\n",
    "    ids = pd.read_csv(IDFileName, sep = '\\t', header = None)\n",
    "    ids_vec = ids.iloc[:,1]\n",
    "    n = len(ids.index)\n",
    "    ids_diag = ['NA' for x in range(n)]\n",
    "    n_off = int(n * (n - 1) / 2)\n",
    "    ## Read relatedness values\n",
    "    grm = np.fromfile(BinFileName, dtype = dt)\n",
    "    i = sum_n_vec(n)\n",
    "    out = {'diag': grm[i], 'off': np.delete(grm, i),'id': ids}\n",
    "    return(out)\n",
    "\n",
    "\n",
    "G = ReadGRMBin(prefix)\n",
    "N = len(G['diag'])\n",
    "GRM = csr_matrix((N, N));GRM_array = GRM.todense().A1.reshape(N, N)\n",
    "idx = np.tril_indices(N,-1,N);idy = np.triu_indices(N,1,N);id_diag = np.diag_indices(N)\n",
    "GRM_array[idx] = G['off'];GRM_array[id_diag] = G['diag'];GRM_array[idy] = GRM_array.T[idy]\n",
    "GRM_array = np.float32(GRM_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the GRM everytime for each trait in the above way is very time-consuming especially when $N$ is large (>$40,000)$. The following few lines of codes can be used to save the loaded GRM in efficient h5py format. \n",
    "\n",
    "Then for analyzing each trait, one would need to load this h5py data to construct the GRM (codes are provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------convert the GRM to h5py format for faster loading------------------- \n",
    "#hf = h5py.File('Data/example_grm.h5', 'w')\n",
    "#hf.create_dataset('dataset_1', data=GRM_array)\n",
    "#hf.close()\n",
    "\n",
    "#-----------------------loading GRM in h5py format------------------------------------------- \n",
    "#hf = h5py.File('Data/example_grm.h5', 'r')\n",
    "#GRM_array= np.array(hf.get('GRM'),dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load and create the phenotype (y) and covariate vectors (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------loading the phenotype and covariate data----------------------------\n",
    "phenotypes = np.loadtxt(\"Data/example_pheno.csv\",skiprows=1)\n",
    "covariates = np.loadtxt(\"Data/example_covar.csv\",delimiter=\",\",skiprows=1)\n",
    "y = phenotypes[:,2]\n",
    "X = np.delete(covariates,[0,1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a random subsample (to be used as set of knots) from the set of all individuals and select the correspondoing rows of y, X and GRM_array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------Knot selection and selecting corresponding vectors----------------------------\n",
    "subsample_size = 500;\n",
    "sub_sample = sorted(np.random.choice(range(0,N),subsample_size,replace=False))\n",
    "non_subsample = np.setdiff1d(range(0,N),sub_sample)\n",
    "indices = np.hstack((sub_sample,non_subsample))\n",
    "GRM_array = np.float32(GRM_array[np.ix_(indices,indices)].T)\n",
    "y = y[indices]; X=X[indices]; X_T = X.T;\n",
    "\n",
    "G_selected = GRM_array[range(0,subsample_size),:][:,range(0,subsample_size)]\n",
    "y_sub = y[range(0,subsample_size)]; X_sub=X[range(0,subsample_size)]; X_subT=X_sub.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we fit a LMM with the selected subsample to estimate heritability ($h^2$) and variance ($\\sigma^2$). The first two elements of \"result_subsample\" vector respectively store the subsample-based heritability and variance estimates. The thrid element is the time taken for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------Fitting LMM using only the selected subsample (set of knots)-------------------------\n",
    "A_selc = np.copy(G_selected)-Identity(subsample_size)\n",
    "result_subsample = derivative_minim_sub(y_sub, X_sub, X_subT, G_selected, A_selc, subsample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the PredLMM likelihood to estimate heritability ($h^2$) and variance ($\\sigma^2$). The first two elements of \"result_full\" vector respectively store PredLMM heritability and variance estimates. The thrid element is the time taken for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------Running PredLMM----------------------------------------------------------------------\n",
    "Ct =  np.copy(GRM_array[range(0,subsample_size),:],order='F')\n",
    "C12 = Ct[:,range(subsample_size,N)]\n",
    "id_diag = np.diag_indices(N)\n",
    "diag_G_sub = GRM_array[id_diag]\n",
    "G_inv = inv(G_selected).T\n",
    "GRM_array[np.ix_(range(subsample_size,N),range(subsample_size,N))] = sgemm(alpha=1,a=C12.T,b=sgemm(alpha=1,a=G_inv,b=C12))\n",
    "del G_inv, C12\n",
    "add = copy(-GRM_array[id_diag] + diag_G_sub) ## diagonal adjustment\n",
    "np.fill_diagonal(GRM_array, - 1 + diag_G_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_full = derivative_minim_full(y, X, X_T, Ct, id_diag, add, G_selected, GRM_array, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we stack both the estimates as the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83936828 0.97270912 0.13463879 0.79496932 1.02671802 2.99898219]\n"
     ]
    }
   ],
   "source": [
    "final_result = np.hstack((result_subsample,result_full))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
